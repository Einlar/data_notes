%&latex
%
\documentclass[../template.tex]{subfiles}
\begin{document}

\section{Continuity of Brownian Path}
\lesson{6}{04/11/19}
Consider a particle starting in $x=0$ at $t=0$, and traversing $N$ points $\{x_i\}_{i=1,\dots,N}$ such that all increments $\Delta x_i = x_i - x_{i-1}$ are \textit{independent} and described by a \textit{gaussian pdf}. The density function for such a trajectory $\{x_i\}$ is the usual product of transition probabilities:
\begin{align}
    \dd{\mathbb{P}}_{t_1, \dots, t_N} (x_1, \dots, x_N) = \left(\prod_{i=1}^N
    \frac{\dd{x_i}}{\sqrt{4 \pi \Delta t_i D}}  \right) \exp\left(-\sum_{i=1}^N  \frac{(\Delta x_i)^2}{4 D \Delta t_i} \right) \quad \substack{\Delta t_i = t_i-t_{i-1}\\ \Delta x_i = x_i - x_{i-1}}
    \label{eqn:dP}
\end{align}
We now show that, taking the continuum limit $\max_i \Delta t_i \to 0$ leads to paths $\{x(\tau)\}$ that are \textit{almost surely continuous}. In other words, for any interval $T \subseteq \mathbb{R}$, the subset $N \subset \mathbb{R}^T$ of functions that are discontinuous has $0$ Wiener measure. 

Mathematically, we want to show that, as $\Delta t_i \to 0$, the probability that $\Delta x_i$ is close to $0$ approaches certainty:   
\begin{align*}
    \lim_{\Delta t_i \to 0} \mathbb{P}(|\Delta x_i| < \epsilon) = 1 \quad \forall \epsilon > 0
\end{align*}   
This is just the probability that, during time $\Delta t_i$, the particle makes a jump of size lower than $\epsilon$:
\begin{align*}
    \mathbb{P}(|\Delta x_i| < \epsilon) &= \mathbb{P}(x_{i-1} - \epsilon< x_{i} < x_{i-1}+\epsilon|x(t_{i-1}) = x_i) =\\
    &= \int_{x_{i-1}-\epsilon}^{x_{i-1}+\epsilon} \frac{\dd{x_i}}{\sqrt{4 \pi D \Delta t_i}} \exp\left(-\frac{(x_i - x_{i-1})^2}{4 D \Delta t_i} \right) =\\
    &\underset{(a)}{=}  \int_{-\epsilon}^{+\epsilon} \frac{\dd{\Delta x_i}}{\sqrt{4 \pi D \Delta t_i}} \exp\left(-\frac{(\Delta x_i)^2}{4 D \Delta t_i} \right)
\end{align*}
where in (a) we translated the variable of integration $\Delta x_i = x_{i}- x_{i-1}$.\\
With another change of variables:
\begin{align*}
    \frac{(\Delta x_i)^2}{\Delta t_i} = z^2 \Rightarrow z = \frac{\Delta x_i}{\sqrt{ \Delta t_i}} \Rightarrow \dd{\Delta x_i} = \dd{z} \sqrt{\Delta t_i}  
\end{align*}
we get:
\begin{align*}
    \mathbb{P}(|\Delta x_i| < \epsilon) = \int_{|z| < \epsilon/\sqrt{\Delta t_i }} \frac{\dd{z}\cancel{\sqrt{\Delta t_i}}}{\sqrt{4 \pi D \cancel{\Delta t_i}}}  \exp\left(-\frac{z^2}{4D} \right)
\end{align*}
And taking the continuum limit leads to:
\begin{align*}
    \lim_{\Delta t_i \to 0} \mathbb{P}(|\Delta x_i| < \epsilon) = \int_{-\infty}^{+\infty} \frac{\dd{z}}{\sqrt{4 \pi D}} \exp\left(-\frac{z^2}{4D} \right) =1
\end{align*}

 

\section{Differentiability of Brownian Path}
With a very similar calculation (here omitted) we can also show that:
\begin{align*}
    \lim_{\Delta t_i \downarrow 0} \left( \left|\frac{\Delta x_i}{\Delta t_i}\right| > k \right) = 1 \quad \forall k > 0
\end{align*}
meaning that Brownian paths are \textit{almost surely everywhere non-differentiable}.

\medskip

Nonetheless, it is sometimes useful to consider \q{formal derivatives} of a Brownian path, that acquire a definite meaning only when considering a \textit{finite discretization}. For example, we can start from (\ref{eqn:dP}) and rewrite it as:
\begin{align*}
    d\mathbb{P}_{t_1, \dots, t_N} (x_1, \dots, x_N) = \left(\prod_{i=1}^N \frac{\dd{x_i}}{\sqrt{4 \pi \Delta t_i }}\right) \exp\left(-\frac{1}{4 D} \sum_{i=1}^N \textcolor{Red}{\Delta t_i} \left(\frac{\Delta x_i}{\textcolor{Red}{\Delta t_i}} \right)^2 \right) 
\end{align*}
Then, in the continuum limit $\Delta t_i \to 0$, the sum in the exponential argument becomes a Riemann integral:
\begin{align*}
    \sum_{i=1}^N \Delta t_i \left(\frac{\Delta x_i}{\Delta t_i} \right)^2 \xrightarrow[\Delta t \to 0]{} \int_0^t \dd{\tau} \underbrace{\left(\frac{\dd{x_i}}{\dd{\tau}} \right)^2}_{\dot{x}^2(\tau)}  \qquad t= t_N
\end{align*} 
where $t = t_N$. Substituting it back leads to:
\begin{align*}
    \dd{x_w}(\tau) = \prod_{\tau = 0^+}^t \frac{\dd{x}(\tau)}{\sqrt{4 \pi D \dd{\tau}}} \exp\left(-\frac{1}{4 D} \int_0^t \dot{x}^2 (\tau) \dd{\tau} \right) 
\end{align*}
This expression has no rigorous meaning in this form ($\dot{x}(\tau)$  \textit{does not} exists!) but can be \textit{formally manipulated} into other expressions that \textit{have} a definite meaning, thus proving useful for the discussion.  

\section{Forces on the particle}
We want now to generalize the framework we obtained to the case of a diffusing particle subject to \textit{external forces}, e.g. a drop of ink diffusing through a water medium in the presence of gravity.

To do this, we first return to the beginning, deduce a Master Equation for a more general \textit{evolution}, and then choose the right probability distribution reproducing the behaviour in presence of forces.

So, let's start by considering a particle moving on a \textit{uniform} one-dimensional lattice ($x_i = i \cdot l$, $t_n = n \cdot \epsilon$), and satisfying the Markovian property, meaning that the probability $W_i(t_{n+1})$ of being at the position labelled by $i$ at the \textit{next time-step} $t_{n+1}$ depends only on the current state $t_n$, that is on the current probabilities $W_j(t_n) \> \forall j$) and on the current transition probabilities $W_{ij}(t_n)$ from $j$ to $i$:
\begin{align}\label{eqn:Markov1}
    W_i(t_{n+1}) = \sum_{j=-\infty}^{+\infty} W_{ij}(t_n) W_j(t_n)
\end{align}

Previously, we assumed that:
\begin{align*}
    W_{ij}(t_n) = \delta_{j,i-1} P_+ + \delta_{j,i+1} P_-
\end{align*}        
Which means that the particle only jumps from adjacent positions, one step at a time, and cannot remain at the same place. This Master Equation leads, in $d=3$ and in the continuum limit, to the usual Diffusion Equation:
\begin{align*}
    \pdv{t} W(\bm{x}, t|\bm{x_0}, t_0) = \nabla^2 W(\bm{x},t | \bm{x_0},t_0)
\end{align*}
%TO DO: insert figures (look at the notebook)

We now consider a more general case, where we drop the discretization of the space domain, allowing \textit{jumps} of \textit{any size} in $\mathbb{R}$. Then (\ref{eqn:Markov1}) becomes:
\begin{align}
    \label{eqn:Markov2}
    W(x,t_{n+1}) \dd{x} = \int_{-\infty}^{+\infty} \dd{z} W(x, t_{n+1}|x-z,t_n) W(x-z,t_n)
\end{align}
The integrand is the probability of the particle being in $[x-z,x-z+\dd{x}]$ at time $t_n$ and making a jump of size $z$ to reach $[x,x+\dd{x}]$ at time $t_{n+1}$. By summing over \textit{all possible jump sizes} we compute the total probability of the particle being \textit{near} the arrival position.

If we require \textit{jumps} to be \textbf{independent} of each other\footnote{This is a stronger requirement than the Markovian property. In fact, \textit{independent increments} imply a \textit{Markov process}, but the converse is not true. See \url{http://statweb.stanford.edu/~adembo/math-136/Markov_note.pdf}}, as it is physically evident by the problem's symmetry, then the \textit{jump} probabilities $W(x,t_{n+1}|x-z,t_n)$ depend only on the \textit{jump size} $z$.  

Assuming a \textit{isolate system}, as the particle cannot \textit{escape}, \textbf{probability is conserved}:
\begin{align*}
    \int_{\mathbb{R}} \dd{x} W(x,t_{n+1}) &\overset{!}{=} \int_{\mathbb{R}} \dd{y} W(y,t_n)\\
    &\underset{(\ref{eqn:Markov2})}{=} \int_{\mathbb{R}} \dd{z} \int_{\mathbb{R}} \dd{x W(x,t_{n+1}|x-z,t_n)} W(x-z,t_n) =\\
    &\underset{(a)}{=} \int_{\mathbb{R}} \dd{z} \int_{\mathbb{R}} \dd{y} W(y+z,t_{n+1}|y,t_n) W(y,t_n) =\\
    &\underset{(b)}{=} \left(\int_{\mathbb{R}} \dd{z} W(\bar{y} + z,t_{n+1}|\bar{y},t_n) \right) \left(\int_{\mathbb{R}} \dd{y} W(y,t_n) \right) \qquad \forall \bar{y} \in \mathbb{R}
\end{align*}
where in (a) we changed variables $x \mapsto y=x-z$, with $\dd{y} = \dd{x}$, and in (b) we used the \textit{independent increments} property ($\bar{y}$ is a arbitrary constant). Comparing the first and last lines leads to:
\begin{align*}
    \int_{\mathbb{R}} \dd{z} W(y+z,t_{n+1}|y,t_n) = 1
\end{align*} 
Intuitively, if the particle \textit{cannot disappear}, it \textit{must make a jump}.   

Here on, for notation simplicity, we denote:
\begin{align*}
    W(y+z,t_{n+1}|y,t_n) \equiv W(+z|y,t_n)
\end{align*}

Starting from (\ref{eqn:Markov2}) and taking the continuum limit in time we can write a \textit{more general} diffusion equation. We start by constructing the difference quotient:
\begin{align*}
    W(x,t_{n+1}) - W(x,t_n) &= \int_{\mathbb{R}} \dd{z} W(+z| x-z, t_n) W(x-z, t_n) - W(x,t_n) =\\
    &= \int_\mathbb{R} \dd{z} W(+z| x-z, t_n) W(x-z, t_n) - \underbrace{\textcolor{Blue}{\int \dd{z} W(+z| x, t_n)}}_{=1} W(x,t_n) =\\
    &= \int_\mathbb{R} \dd{z} \Big[\underbrace{W(+z| x-z,t_n) W(x-z, t_n) }_{F_z(x-z)} - \underbrace{W(+z|x,t_n) W(x,t_n)}_{F_z(x)} \Big] =\\
    &= \int_{\mathbb{R}} \dd{z} \left[F_z(x-z) - F_z(x)\right] = \\
    &\underset{(a)}{=} \int_{\mathbb{R}} \dd{z} \left[\cancel{F_z(x)} -z \pdv{x} F_z(x) + \frac{z^2}{2} \pdv[2]{x} [F_z(x)] +\dots - \cancel{F_z(x)}\right] = \\
    &=-\int_{\mathbb{R}} \dd{z} z \pdv{x} [F_z(x)] + \frac{1}{2} \int_\mathbb{R} \dd{z} z^2 \pdv[2]{x} [F_z(x)] + \dots =\\
    &\underset{(b)}{=} -\pdv{x} \Bigg[\underbrace{\left(\int_{\mathbb{R}} \dd{z} z\,W(+z|x,t_n)\right)}_{\mu_1(x,t_n)} W(x,t_n)\Bigg]  +\\
    &\quad\> + \frac{1}{2} \pdv[2]{x} \Bigg[\underbrace{\left(\int_{\mathbb{R}} \dd{z} z \, W(+z|x,t_n)\right)}_{\mu_2(x,t_n)} W(x,t_n)\Bigg] + \dots
\end{align*}
where $F_z(x)$ is the probability of a \textit{jump} of size $z$ from the position $x$. In (a) we expanded $F_z$ about $x$, and in (b) we exchanged the order of integrals and derivatives. Then we define the $k$-th moment of the \textit{jump} pdf as follows:
\begin{align*}
    \mu_k(x,t) = \int_{\mathbb{R}} \dd{z} z^k \, W(+z|x,t)
\end{align*}  
This allows us to rewrite the above difference in a more compact form:
\begin{align*}
    W(x,t_{n+1}) - W(x,t_n) &= \sum_{k=1}^{+\infty} \frac{(-1)^k}{k!} \pdv[k]{x} \left(\mu_k(x,t_n) W(x,t_n)\right) 
\intertext{Physically, as probability is conserved, by the continuity equation, the \textit{change} in probability density equals the divergence of a \textit{flux}, which is just the $x$ derivative in this one-dimensional case. So, if we \textit{extract} a derivative, we can write the flux explicitly:}
&= \pdv{x}\left(\sum_{k=1}^{+\infty} \frac{(-1)^k}{k!} \pdv[k-1]{x}(\mu_k(x,t_n) W(x,t_n)) \right)\\
&\equiv -\pdv{x} J(x,t_n)
\end{align*}
where $J(x,t_n)$ is the \textit{outward flux} at $x$, meaning that if $J>0$, then $W(x,t_{n+1}) < W(x,t_n)$ (the particle \textit{escapes} from $x$ to another place), and otherwise if $J<0$ we have $W(x,t_{n+1}) > W(x,t_n)$ (the particle is \textit{sucked in} $x$).

If we integrate both sides over $x$ and apply the probability conservation we get the boundary conditions for the flux:
\begin{align*}
    \int_{\mathbb{R}} (W(x,t_{n+1}) - W(x,t_n)) \dd{x} &= \int_{\mathbb{R}} \dd{x } \left(-\pdv{x} J(x,t_n)\right)\\
    1-1 &= -J(x,t_n) \Big|_{-\infty}^{+\infty} = J(-\infty,t_n) - J(+\infty,t_n)
\end{align*}
This means that, in a \textit{isolate system}, the \textit{flux} at $\pm \infty$ must be the same.  

Finally, normalizing by the time interval we get the complete difference quotient, which will become a time derivative in the continuum limit.
\begin{align}
    \frac{W(x,t_{n+1})- W(x,t_n)}{t_{n+1}-t_n} = \pdv{x} \left\{
    \sum_{k=1}^\infty \frac{(-1)^k}{k!}  \pdv[k-1]{x} \frac{\mu_k(x,t_n) W(x,t_n)}{t_{n+1}-t_n} 
    \right\}
    \label{eqn:rapporto-incrementale} 
\end{align}
Letting $t_{n+1}-t_n=\epsilon$, in the limit $\epsilon \to 0$  the left side will be $\dot{W}(x,t)$.

\medskip

All that's left is to find an explicit definition for the \textit{jump pdf} $W(+z|x,t)$. Previously, we assumed a \textbf{gaussian} pdf for the displacements:
\begin{align*}
    z \sim \frac{1}{\sqrt{4 \pi D \epsilon}}  \exp\left(-\frac{(\Delta x)^2}{4 D \epsilon} \right)
\end{align*} 
With this choice, the first two moments become:
\begin{align*}
    \mu_1 = 0 \qquad \mu_2 = 2 D \epsilon
\end{align*}
And the variance:
\begin{align*}
    \operatorname{Var}(z) =  \mu_2 - \mu_1^2 = 2 D \epsilon \propto \epsilon 
\end{align*}

However, for a particle subject to a force we would expect to have a \textit{preferred jump direction}, leading to a \textit{constant velocity motion} in the direction of the force. So we require a different $\mu_1$: 
\begin{align*}
    \langle z \rangle = \mu_1 = \int_{\mathbb{R}} z W(+z|x,t) \propto \epsilon f(x)
\end{align*} 
We still want to fix the variance to be proportional to $\epsilon$, as it is expected in a diffusion process. 

An appropriate choice for such a distribution is given by:
\begin{align}
    W(+z|x,t) = F\left(\frac{z-\epsilon f(x,t)}{\sqrt{\epsilon \hat{D}(x,t)}} \frac{1}{\sqrt{\epsilon \hat{D}(x,t)}}  \right)
    \label{eqn:Fbig}
\end{align}
with $F, \hat{D}\colon \mathbb{R} \to \mathbb{R}$ functions, satisfying certain conditions, and with a physical meaning that we will now see.

First of all, we check the normalization:
\begin{align*}
    1 \overset{!}{=} \int_{\mathbb{R}} \dd{z} W(+z|x,t)  = \frac{1}{\sqrt{\epsilon \hat{D}(x,t)}} \int_{\mathbb{R}} \dd{z} F\left(\frac{z-\epsilon f(x,t)}{\sqrt{\epsilon \hat{D}(x,t)}} \right) \underset{(a)}{=} \int_{\mathbb{R}} \dd{y} F(y)  
\end{align*}
where in (a) we changed variables:
\begin{align}
    y = \frac{z-\epsilon f(x,t) }{\sqrt{\epsilon \hat{D}(x,t)}} \qquad \dd{z} = \sqrt{\epsilon \hat{D}(x,t)} \dd{y}  \label{eqn:cov1}
\end{align}
Then we compute the first moment:
\begin{align*}
    \langle z \rangle &= \mu_1(x,t) = \int_{\mathbb{R}} \dd{z} z \, F\left(\frac{z- \epsilon f(x,t)}{\sqrt{\epsilon \hat{D}(x,t)}} \right) \frac{1}{\sqrt{\epsilon \hat{D}(x,t)}} =\\
    &\underset{(\ref{eqn:cov1})}{=} \int_{\mathbb{R}} \dd{y} \left(\epsilon f(x,t) + y \sqrt{\epsilon \hat{D}(x,t)}\right) F(y) = \\
    &= \epsilon f(x,t) \underbrace{\int_{\mathbb{R}} F(y) \dd{y}}_{=1} + \sqrt{\epsilon \hat{D}(x,t)} \int_{\mathbb{R}} yF(y) \overset{!}{=} \epsilon f(x,t)
\end{align*}
So, in order to have the right normalization and the desired $\langle z \rangle$ we need:
\begin{align*}
    \begin{cases}
        \int_{\mathbb{R}} \dd{y} F(y) = 1\\
        \int_{\mathbb{R}} \dd{y} y F(y) = 0
    \end{cases}
\end{align*}
Both conditions are satisfied, for example, by all even normalized functions.

For the second moment:
\begin{align*}
    \mu_2(x,t) &= \frac{1}{\sqrt{\epsilon \hat{D}(x,t)}} \int_{\mathbb{R}} \dd{z} z^2  F\left(\frac{z-\epsilon f(x,t)}{\sqrt{\epsilon \hat{D}(x,t)}} \right) =\\
    &\underset{(\ref{eqn:cov1})}{=} \int_{\mathbb{R}} \dd{y} (\epsilon f(x,t) + y \sqrt{\epsilon \hat{D}(x,t)})^2 F(y) =\\
    &= \int_{\mathbb{R}} \dd{y} F(y) [\epsilon^2 f^2 + y^2 \hat{D} \epsilon + \cancel{2 \epsilon \sqrt{\epsilon} \hat{D} f y}] =\\
    &= \epsilon^2 f^2 + \hat{D} \epsilon \int_{\mathbb{R}} \dd{y} y^2 F(y) = \epsilon^2 f^2 + \hat{D} \epsilon \langle y^2 \rangle_{F(y)}
\end{align*}
And so the variance becomes:
\begin{align*}
    \operatorname{Var}(z) = \mu_2 - \mu_1^2 = \epsilon \hat{D} \langle y^2 \rangle_{F(y)} \propto \epsilon
\end{align*}
which is proportional to $\epsilon$ as desired. For notational simplicity, we introduce a new function $D\colon \mathbb{R} \to \mathbb{R}$ such that:
\begin{align*}
    \operatorname{Var}(z) = \epsilon\hat{D} \langle y^2 \rangle_{F(y)} \equiv 2 D(x,t) \epsilon \Rightarrow \mu_2(x,t) = \epsilon^2 f^2 + 2 D(x,t)   
\end{align*} 

We note that higher order moments are all of order $O(\epsilon^{3/2})$. For example, the third moment is:
\begin{align*}
    \mu_3(x,t) &= \frac{1}{\sqrt{\epsilon \hat{D}(x,t)} \int_{\mathbb{R}}} \dd{z} z^2 F\left(\frac{z- \epsilon f(x,t)}{\sqrt{\epsilon \hat{D}(x,t)}} \right) = \\ 
    &\underset{(\ref{eqn:cov1})}{=} \int_{\mathbb{R}} \dd{y} (\epsilon f(x,t) + y \sqrt{\epsilon \hat{D}(x,t)})^3 F(y) =\\
    &= \int_{\mathbb{R}} \dd{y} \left(\epsilon^3 f^3 + y^3 (\epsilon \hat{D})^{3/2} + \cancel{3 \epsilon^2 f^2 y \sqrt{\epsilon \hat{D}}} + 3 \epsilon^2 f \hat{D} y^2\right) F(y) =\\
    &= \epsilon^3 f^3 + (\epsilon \hat{D})^{3/2} + 3 \epsilon^2 f \hat{D} \langle y^2 \rangle_{F(y)} = O(\epsilon^{3/2})
\end{align*} 

Substituting back (\ref{eqn:Fbig}) in (\ref{eqn:rapporto-incrementale}) we arrive to:
\begin{align*}
    \frac{W(x, t_{n+1}) - W(x,t_n)}{\epsilon} &= -\pdv{x} \Bigg[W(x,t_n) \underbrace{\frac{\mu_1(x,t_n)}{\epsilon}}_{f(x,t)}  \Bigg] + \frac{1}{2} \pdv[2]{x} \Bigg[ \underbrace{\frac{\mu_2(x,t_n)}{\epsilon}}_{\epsilon f^2 + 2D(x,t)}  W(x,t_n)\Bigg]  +\\
    &\quad\>\>+ \underbrace{\frac{1}{3!} \pdv[3]{x} \Bigg[W(x,t_n) \frac{\mu_3 (x,t_n)}{\epsilon} \Bigg] + \dots}_{O(\epsilon^{1/2})} 
\end{align*}

Taking the limit $\epsilon \to 0$, we are left with:
\begin{align*}
    \pdv{W(x,t)}{t} &= -\pdv{x}[f(x,t) W(x,t)] + \frac{1}{\cancel{2}} \pdv[2]{x}[\cancel{2} D(x,t)W(x,t)] =\\
    &= - \pdv{x} \Big[f(x,t) W(x,t) - \pdv{x} \big(D(x,t) W(x,t)\big)\Big]  
\end{align*} 
This is the \textbf{Fokker-Planck equation}, describing the diffusion process in the presence of a \textit{force} $f(x,t)$, and a diffusion parameter $D(x,t)$.

Note that, in absence of forces $f(x,t) \equiv 0$ and with a constant diffusion $D(x,t) \equiv D$ we retrieve the usual \textit{diffusion equation}:
\begin{align*}
    \pdv{t} W(x,t) = D \pdv[2]{x}W(x,t)
\end{align*}     

\section{Langevin equation}
The Fokker-Planck equation involves \textit{probability distributions}, meaning that it describes the behaviour of \textit{ensembles of trajectories} at once. However, we can find an equivalent description by focusing on a \textit{single path}. 

We start with a Wiener process, that is a stochastic process with \textit{independent} and \textit{gaussian} increments and \textit{continuous} paths. Considering a time discretization $\{t_i\}$, the evolution of a single trajectory is described by:
\begin{align}
    x(t_{i+1}) = x(t_i) + \Delta x(t_i) \label{eqn:increment}
\end{align}
where each increment $\Delta x(t_i)$ is sampled from a gaussian pdf:
\begin{align*}
    \Delta x_i(t_i) \sim \frac{1}{\sqrt{4 \pi D \Delta t_i}} \exp\left(-\frac{(\Delta x)^2}{4 D \Delta t_i} \right) 
\end{align*}
To simplify notation, we change variables, so that:
\begin{align*}
    \frac{\Delta B^2}{2} = \frac{\Delta x^2}{4 D} \Rightarrow \Delta B = \frac{\Delta x}{\sqrt{2 D}}    
\end{align*}
If $x \sim p(x)$, and $y = y(x) \sim g(y)$, then by the rule for a change of random variables we have:
\begin{align*}
    g(y) = p(x(y)) \dv{x(y)}{y}(x(y))
\end{align*}
In this case:
\begin{align*}
    \Delta B \sim \frac{1}{\sqrt{4 \pi D \Delta t_i }} \exp\left(-\frac{(\Delta B)^2}{2 \Delta t_i} \right) \underbrace{\dv{\Delta x}{\Delta B}}_{\sqrt{2 D}} = \frac{1}{\sqrt{2 \pi \Delta t_i}} \exp\left(-\frac{(\Delta B)^2}{2 \Delta t_i} \right)  
\end{align*}
Note that now $\langle \Delta B^2(t_i) \rangle = \Delta t_i$, leaving out the $D$.

Substituting in (\ref{eqn:increment}) and rearranging we get:
\begin{align}
    x(t_{i+1}) - x(t_i) = \sqrt{2 D} \Delta B(t_i)  \label{eqn:increment2}
\end{align}
We want now to form a time derivative in the left side, in order to arrive a (stochastic) differential equation for paths. To do this, we first extract a $\Delta t_i$ factor from $\Delta B(t_i)$ by performing another change of variables:
\begin{align}
    \Delta B(t_i) \equiv \Delta t_i \xi(t_i) 
    \label{eqn:deltaB}
\end{align}  
so that $\Delta x_i = \sqrt{2D} \Delta t_i \xi_i$, and all the \textit{randomness} is now contained in the random variable $\xi$, which is distributed according to:
\begin{align*}
    \xi(t_i) \sim \frac{1}{\sqrt{2 \pi \Delta t_i}} \exp\left(-\frac{\Delta t_i^2 \xi_i^2}{2 \Delta t_i} \right) \underbrace{\dv{\Delta B_i}{\xi (t_i)}}_{\Delta t_i} = \sqrt{\frac{\Delta t_i}{2 \pi} } \exp\left(-\frac{\Delta t_i }{2} \xi_i^2 \right) \qquad \xi_i \equiv \xi(t_i)  
\end{align*}   
Substituting back in (\ref{eqn:increment2}) and dividing by $\Delta t_i$ leads to:
\begin{align*}
    \frac{x(t_{i+1})-x(t_i)}{\Delta t_i}  = \sqrt{2D} \xi(t_i)
\end{align*}
And by taking the continuum limit $\Delta t_i \to 0$ we get the \textbf{Langevin equation} for a Brownian particle:
\begin{align}
    \dot{x}(t) = \sqrt{2D} \xi(t)
    \label{eqn:langevin1}
\end{align}
We can see $\xi(t)$ as a \textit{highly irregular, quickly varying function}, which, in a certain sense, expresses the result of Brownian collisions at a certain instant. In particular, the following holds:
\begin{align*}
    \langle \xi(t) \rangle = 0 \qquad \langle \xi(t) \xi(t') \rangle = \delta(t-t')
\end{align*}
meaning that the values of $\xi(t)$ at different instants are completely \textit{independent}. 
\medskip

Note that, as we saw previously, Brownian paths are not differentiable - and so $\dot{x}(t)$ does not exist, and this is just a \textit{formal} equation, with a definite meaning only in a given \textit{discretization}. Also, note that $\xi(t)$ is a random variable, and so this is an example of a \textbf{stochastic differential equation}. It is not clear how to find a solution to such an equation, or even how to \textit{define} what a solution should be - and this will be the main topic of the next section.

We can rewrite (\ref{eqn:langevin1}) in a more \textit{rigorous} form by \q{multiplying by $\dd{t}$}, i.e. performing the change of variables (\ref{eqn:deltaB}), which - in the continuum limit - is $\dd{B} = \xi \dd{t}$, leading to:
\begin{align*}
    \dd{x(t)} = \sqrt{2 D} \dd{B} \qquad \dd{B} \sim \frac{1}{\sqrt{2 \pi \dd{t}}} \exp\left(-\frac{\dd{B}^2}{2 \dd{t}} \right) 
\end{align*}  

\begin{comment}
\begin{align*}
    \xi(t_i) \sim \sqrt{\frac{\Delta t_i}{2 \pi} } \exp\left(-\frac{\Delta t_i \xi_i^2}{2 } \right)
\end{align*}  
and then:
\begin{align*}
    P(\xi \dots ) \propto \exp\left(-\frac{1}{2} \int \xi^2 (\tau) \dd{\tau} \right)
\end{align*}
and $\langle \xi(\tau) \rangle = 0$, $\langle \xi (\tau) \xi (\tau') \rangle = \delta(\tau - \tau')$.
\end{comment}

Before moving on, we want to generalize this equation to the presence of \textit{external forces}. As we saw previously, this just results in adding a \textit{constant velocity motion} to the particle, leading to the full \textbf{Langevin equation}: 
\begin{align}\nonumber
    \dot{x}(t) &= f(x,t) + \sqrt{2 D(x,t)}\xi(t)\\
    \dd{x(t)} &= f(x,t) \dd{t} + \sqrt{2 D(x,t)} \dd{B} \qquad \dd{B} \sim \frac{1}{\sqrt{2 \pi \dd{t}}} \exp\left(-\frac{\dd{B}^2}{2 \dd{t}} \right) 
    \label{eqn:L-eq}
\end{align} 

The \textit{physical} meaning of $f(x,t)$ and $D(x,t)$ can be more clearly seen by comparing (\ref{eqn:L-eq}) to the equation of motion of the Brownian particle.

Consider a particle of mass $m$ immersed in a fluid, with a radius $a$ that is much larger than the surrounding molecules (typically $\sim 10^{-9}$ to \SI{e-7}{\m}). The forces acting on it will be that of \textit{viscous friction} $-\gamma \dot{\bm{r}}$, eventual \textit{external forces} $\bm{F}_{\mathrm{ext} }$ (e.g. gravity), and a rapidly varying and \textit{random} term $\bm{F}_{\mathrm{noise}}$, encompassing the effect of the large number of collisions ($\sim 10^{12}/\si{\s}$) with the smaller fluid particles:   
\begin{align*}
    m \ddot{\bm{r}} (t) = - \gamma\dot{\bm{r}} + \bm{F}_{\mathrm{ext} } + \bm{F}_{\mathrm{noise} }(t)
\end{align*}
Dividing both sides by $\gamma$:
\begin{align}
    \frac{m}{\gamma} \ddot{\bm{r}}(t) = - \dot{\bm{r}} + \frac{\bm{F}_{\mathrm{ext} }(\bm{r},t)}{\gamma} + \frac{\bm{F}_{\mathrm{noise} }(t)}{\gamma}  
    \label{eqn:N1}
\end{align}
Assuming a spherical particle, $\gamma$ is given by Stokes law to be $6 \pi a \eta$, where $\eta$ is the viscosity of the surrounding fluid. 

Note that, if we ignore the external force and the random term, the equation becomes:
\begin{align*}
    \dv{\dot{\bm{r}}(t)}{t} = -\frac{\gamma}{m} v(t) 
\end{align*}
which has solution:
\begin{align*}
    \dot{\bm{r}}(t) = \exp\left(-\frac{t}{\tau_B} \right) \dot{\bm{r}}(0) \qquad \tau_B = \frac{m}{\gamma} 
\end{align*}
$\tau_B$ is in the scale of $\SI{e-3}{\s}$, and represents the timescale of reaching equilibrium, i.e. $0$ velocity. So, for Brownian motion to happen, $\bm{F}_{\mathrm{noise}}$ is necessary. Also, if we are interested in the motion on the scale of seconds, we can neglect the acceleration term. This is the \textbf{overdamped limit} (in analogy to a damped oscillator with high loss of energy due to attrition, so that it quickly reaches equilibrium without ever \q{overshooting}). Given that assumption, (\ref{eqn:N1}) becomes: 
\begin{align*}
    \dot{\bm{r}} = {\frac{\bm{F}_{\mathrm{ext} }}{\gamma}}  + \frac{\bm{F}_{\mathrm{noise} }}{\gamma}
\end{align*}
Which, for a particle moving in one dimension, reduces to:
\begin{align*}
    x(t) = \underbrace{\frac{F_{\mathrm{ext}}}{\gamma}}_{f(x,t)}  + \underbrace{\frac{F_{\mathrm{noise}}}{\gamma}}_{\sqrt{2 D(x,t)}\xi(t)}   
\end{align*}
Comparing with (\ref{eqn:L-eq}) gives the physical meaning of $f(x,t)$ and $D(x,t)$.

\end{document}
