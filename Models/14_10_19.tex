%&latex
%
\documentclass[../template.tex]{subfiles}
\begin{document}

\lesson{4}{14/10/19}

\textbf{Summary of the last lessons}.
Analysing the dynamics of the Diffusion Problem led to the Master Equation, which in the symmetrical case reduces to:
\begin{align}
    w_i(t_{n+1}) = \frac{1}{2}(w_{i-1}(t_n) + w_{i+1}(t_n)) 
    \label{eqn:master_equation}
\end{align}
where $w_i(t_n)$ is the (mass) probability function for a particle, i.e. $w_i(t_n)$ is the probability that a particle will be at position $x_i = i\cdot l$ at time $t_n = n \cdot \epsilon$.\\
Further evaluation, in terms of the Binomial distribution, leads to the exact solution:
\begin{align}
    w_i(t_n) = \frac{1}{2^n} {n\choose n_+} 
    \label{eqn:discrete_sol}
\end{align}
where $n_+$ is a random variable representing the number of steps in which the particle moves to the \textit{right}.\\
Then we considered the continuum limit, with $l, \epsilon \downarrow 0$ (keeping $l^2 \epsilon^{-1} = 2D$ constant), arriving to:
\begin{align}
    w_i(t_n) = \frac{1}{\sqrt{4 \pi D t}} \exp\left(-\frac{x^2}{4 D t} \right)
    \label{eqn:solution-from-discrete} 
\end{align} 
which is the pdf for a particle that starts at $x=0$ at $t=0$.

\section{Continuum limit of the Master Equation}
The same result can be obtained by taking directly the continuum limit of the ME (\ref{eqn:master_equation}), which will lead to a differential equation that can \marginpar{Not so sure about this part}
\textit{then} be solved.\\
We start by recalling that, for a fine discretization, $w_i(t_n)$ is approximately equal to the probability of being around a generic $(x,t)$ (i.e. $W(x,t)\Delta x$), up to a normalization constant:
\begin{align*}
    W(x_0,t_n)\Delta x = \mathbb{P}(x \in [x_0 - \Delta x/2, x_0 + \Delta x/2]) \approx \frac{\Delta x}{2l} w_{i_0}(t_n) \qquad i_0 = \lfloor \Delta x/l \rceil
\end{align*} 
And so, with a slight abuse of notation:
\begin{align*}
    w_i(t_n) \approx 2l W(x,t) \qquad i = \lfloor x/l \rceil, n = \lfloor t/\epsilon \rceil
\end{align*}
Substituting in (\ref{eqn:master_equation})
leads to:
\begin{align}
    \cancel{2l} W(x,t+\epsilon) = \cancel{2l}\frac{1}{2}(W(x-l,t) + W(x+l,t))
    \label{eqn:master_2} 
\end{align}
which means that an analogous Master Equation holds even for $W(x,t)$, which is a continuous pdf, and thus can be differentiated. In particular, we can compute $W(x,t+\epsilon)$ in terms of $W(x,t)$ (and derivatives) by expanding around $\epsilon = 0$:
\begin{align}
    W(x,t+ \epsilon) &= W(x,t) + \epsilon \pdv{\tau}W(\chi, \tau) \Big|_{(x,t)} + \frac{\epsilon^2}{2} \pdv[2]{\tau} W(\chi, \tau)\Big|_{(x,t)} + O(\epsilon^3) \label{eqn:time_der}
\intertext{And also $W(x \pm l, t)$ by expanding around $l = 0$:}
W(x \pm l, t) &= W(x,t) \pm l\pdv{\chi}W(\chi,\tau)\Big|_{(x,t)} + \frac{l^2}{2} \pdv[2]{\chi} W(\chi, \tau)\Big|_{x,t} + O(l^3) \label{eqn:space_der}
\end{align} 
We then introduce the following notation for the space and time derivatives:
\begin{align*}
    \dot{W}(x,t) = \pdv{\tau} W(\chi, \tau)\Big|_{(x,t)} \qquad W'(x,t) = \pdv{\chi} W(\chi, \tau)\Big|_{(x,t)}
\end{align*}
so that a space derivative is denoted with $a'$ ($a''$ for the second derivative), and a time derivative with $\dot{a}$ ($\ddot{a}$ for the second derivative).\\
We can now substitute back in (\ref{eqn:master_2}). We start with the right side:
\begin{align*}
    W(x+l,t) + W(x-l, t) = 2 W(x,t) + l^2 W''(x,t) + O(l^4)
\end{align*}
where the $O(l^4)$ is given by the cancellation of the odd powers (including $l^3$). Equating to the left side of (\ref{eqn:master_2}) leads to:  
\begin{align*}
    \cancel{W(x,t)}+ \epsilon \dot{W}(x,t) + \frac{\epsilon^2}{2} = \cancel{W(x,t)} + \frac{l^2}{2} W''(x,t) + O(l^4)  
\end{align*}
Dividing by $\epsilon$:
\begin{align*}
    \dot{W}(x,t) + \frac{\epsilon}{2} \ddot{W}(x,t) &= \underbrace{\frac{l^2}{2 \epsilon}}_{D}  W''(x,t) + O\left(\frac{l^4}{\epsilon} \right)  \\
    &= D W''(x,t) + O(4 \epsilon D^2)
\end{align*} 
If we now take the continuum limit, then $\epsilon, l \to 0$ with the ratio $D = l^2/(2\epsilon)$ fixed, both $\ddot{W}(x,t)$ and the error term vanish, leading to the \textbf{diffusion equation}: 
\begin{align}
    \dot{W}(x,t) = D W''(x,t)
    \label{eqn:diffusion-equation}
\end{align}  

\subsection{Solution of the Continuous Master Equation}
We want now to solve (\ref{eqn:diffusion-equation}), and show that the solution will be the same we previously derived in (\ref{eqn:solution-from-discrete}).\\
So, we start from:
\begin{align*}
    \partial_t W(x,t) = D \partial_x^2 W(x,t)
\end{align*}
This is a second order partial differential equation. To be able to solve it, we must first define its \textbf{boundary conditions}. In this case, we suppose that the particle is unconstrained, and so the spatial domain coincides with $\mathbb{R}$.\\
As $W(x,t)$ is a pdf, the following conditions must hold:
\begin{align*}
    W(x,t) \geq 0 \quad \forall (x,t) \qquad \int_{\mathbb{R}} W(x,t) = 1
\end{align*}   
From the normalization, it follows that $W(x,t)$ - and its spatial derivative $W'(x,t)$ - must vanish as $|x| \to \infty$, so that the integral does not diverge:
\begin{align}
    \lim_{|x| \to \infty} W(x,t) = 0 \qquad \lim_{|x| \to \infty} W'(x,t) = 0
    \label{eqn:boundary-conditions}
\end{align}   
However, it is not obvious that $W(x,t) \geq 0$ will always hold, assuming we choose an initial condition $W(x,t_0) \geq 0$. This will be obvious \textit{a posteriori} - and in fact can justified by the peculiar properties of this differential equation.\\

To solve (\ref{eqn:diffusion-equation}), as the spatial domain is all $\mathbb{R}$, one standard technique is that of the Fourier integral transform, which allows us to \q{remove} derivatives by replacing $\partial_x \psi \to ik\psi$, $\partial_{xx} \to -k^2 \psi$. Thus, if we can \q{remove} the second-order space derivative, we will be left with a much more simpler first order differential equation in the time variable.

\begin{expl}
    \textbf{Translational invariance}. This approach is suggested by the translational invariance of solutions of (\ref{eqn:diffusion-equation}). In fact, if $W(x,t)$ is a solution, then also $\tilde{W}(x,t) = W(x-a,t)$ is a solution.\\
    The generator of the translations is the \textit{momentum}, and its eigenfunctions are the \textit{plane waves}, i.e. the Fourier basis. So, by expressing a function in this base, we will harness the equation's symmetry - simplifying the problem.\\
    In other words, the Fourier basis diagonalizes the Laplacian operator which appears in (\ref{eqn:diffusion-equation}):
    \begin{align*}
        \partial_x^2 \varphi_k(x) = \lambda_k \varphi_k(x) \qquad \lambda_k \equiv -k^2 \qquad \varphi_k(x) = A_k e^{\pm i k x}, k \in \mathbb{R}
    \end{align*}
    In a general case, the Fourier integral trick can be tried for every variable, starting from the one with the higher order derivative, and then the case which leads to the most simplification can be pursued.
\end{expl}

We start by rewriting $W(x,t)$ as a (infinite) linear combination of vectors of the Fourier basis: 
\begin{align}
    W(x,t) = \int_{\mathbb{R}} \frac{\dd{k}}{2 \pi} e^{ikx} c_k(t) 
    \label{eqn:fourier-w}
\end{align}
where the $2\pi$ factor is just a normalization convention.\\
Let $\varphi_k(x) = e^{ikx}$. Then, as the Fourier basis is orthonormal, the following holds (recalling the Fourier transform of the $\delta$ function):
\begin{align}\label{eqn:fourier-ON}
    \langle \varphi_k, \varphi_{k'} \rangle &= \int_{\mathbb{R}} \dd{x} \varphi_k^*(x) \varphi_{k'}(x) = \int_{\mathbb{R}} \dd{x} e^{i(k'-k)x} = 2\pi \delta(k-k')\\ \nonumber
    \langle \tilde{\varphi}_x, \tilde{\varphi}_{x'} \rangle &= \int_{\mathbb{R}} \dd{k} \varphi_k^*(x) \varphi_k(x') = 2 \pi\delta(x-x') 
\end{align} 
We then apply a Fourier transform to both members of (\ref{eqn:fourier-w}), by multiplying by $e^{-ik'x}$ and integrating over $x$:
\begin{align*}
    \int_{\mathbb{R}} W(x,t) e^{-ik'x} \dd{x} &= \int_{\mathbb{R}} \frac{\dd{k}}{2\pi}  \int_{\mathbb{R}} \dd{x} e^{i(k-k')x} c_k(t)
\intertext{If we now apply the ON relation (\ref{eqn:fourier-ON}) we can solve the integral in the right side:}
    \int_{\mathbb{R}} W(x,t) e^{-ik'x}\dd{x} &= \int_{\mathbb{R}} \dd{k} \delta(k-k') c_k(t) = c_{k'}(t)
\end{align*}
And substituting $k' \to k$ we arrive at an expression for $c_k(t)$:  
\begin{align}
    c_k(t) = \int_{\mathbb{R}} \dd{x} e^{-ikx} W(x,t)
    \label{eqn:ckt}
\end{align}
Starting from (\ref{eqn:diffusion-equation}) we can write a corresponding differential equation for the coefficients $c_k(t)$ in the Fourier basis, and then solve it. 

\begin{expl}
    \textbf{Braket notation}. Let the solution be $\ket{W(t)}$, so that $\braket{x}{W(t)} = W(x,t)$. Then in (\ref{eqn:fourier-w}) we just did a change of basis (by using Dirac completeness):
    \begin{align*}
        \ket{W(t)} = \bb{I} \ket{W(t)} = \int_k \ket{k}\underbrace{\braket{k}{W(t)}}_{c_k(t)} 
    \end{align*}
    where $\ket{k}$ are elements of the Fourier basis ($\braket{x}{k} = e^{ikx}$) and so:
    \begin{align*}
        c_k(t) = \braket{k}{W(t)} = \int_x \braket{k}{x} \braket{x}{W(t)} = \int_{\mathbb{R}} \dd{x} e^{-ikx} W(x,t)
    \end{align*}
    So the initial differential equation (\ref{eqn:diffusion-equation}) is expressed in the position basis, while the following equation involving $c_k(t)$ is expressed in the Fourier basis. 
\end{expl}
So, we start by differentiating (\ref{eqn:ckt}) with respect to $t$:
\begin{align*}
    \dot{c}_k(t) &= \int_{\mathbb{R}} \dd{x} e^{-ikx} \dot{W}(x,t) \underset{(a)}{=}  D \int_{-\infty}^{\infty} e^{-ikx} W''(x,t) \dd{x} =  \\
    &\underset{(b)}{=}  \cancel{D W'(x,t) e^{-ikx}}\big|_{-\infty}^{\infty} - D \int_{-\infty}^{\infty} \partial_x (e^{-ikx}) W'(x,t) \dd{x} = \\
    &\underset{(c)}{=}  -D\underbrace{(\partial_x e^{-ikx})}_{-ik e^{-ikx}} \cancel{W(x,t) }\big|_{-\infty}^{\infty} + D\int_{\mathbb{R}} \underbrace{\partial_x^2 (e^{-ikx})}_{-k^2 e^{-ikx}} W(x,t) \dd{x} =\\
    &= -Dk^2 \underbrace{\int_{-\infty}^{+\infty} \dd{x} e^{-ikx} W(x,t)}_{c_k(t)} = -Dk^2 c_k(t)  \\
\end{align*} 
where in (a) we substituted (\ref{eqn:diffusion-equation}), and in (b) and (c) we performed two integrations by parts. Note that the $W(x,t)$ and $W'(x,t)$ terms vanish because of the boundary conditions (\ref{eqn:boundary-conditions}).  

Summarizing:
\begin{align*}
    \dot{c}_k(t) = \int_{\mathbb{R}} \dd{x} e^{-ikx} \dot{W}(x,t) = - D k^2 c_k(t)
\end{align*}
This is a first-order ordinary differential equation, which can be solved by separation of variables:
\begin{align*}
    \dv{t} c_k(t) = -Dk^2 c_k(t) \Rightarrow \int \frac{\dd{c_k(t)}}{c_k(t)} = \int -Dk^2 \dd{t}  \Rightarrow \ln c_k(t) = - Dk^2 t + C
\end{align*}
And rearranging:
\begin{align}
    c_k(t) = A e^{-Dk^2 t}
    \label{eqn:gen-int1}
\end{align}
To find the integration constant $A$ we impose the initial conditions, i.e. that $c_k(t)$ be equal to a known $c_k(t_0)$ at time $t_0$:
\begin{align}
    c_k(t_0) \overset{!}{=} A e^{-Dk^2 t_0} \Rightarrow A = c_k(t_0 ) e^{Dk^2 t_0} 
    \label{eqn:A-const}
\end{align}     
And substituting (\ref{eqn:A-const}) back in (\ref{eqn:gen-int1}) we arrive at the general integral:
\begin{align}
    c_k(t) = c_k(t_0 ) e^{-Dk^2(t-t_0)}
    \label{eqn:ckt2}
\end{align}
We can now go back to $W(x,t)$ by plugging (\ref{eqn:ckt2}) into (\ref{eqn:fourier-w}):
\begin{align} \nonumber
    W(x,t) &= \int_{\mathbb{R}} \frac{\dd{k}}{2 \pi} e^{ikx} c_k(t) = \int_{\mathbb{R}} \frac{\dd{k}}{2 \pi} e^{ikx - Dk^2(t-t_0 )} c_k(t_0) =\\ \nonumber
    &\underset{(\ref{eqn:ckt})}{=} \int_{\mathbb{R}} \frac{\dd{k}}{2 \pi} e^{ikx - Dk^2 (t-t_0 )} \int_{\mathbb{R}} \dd{y} e^{-iky} W(y,t_0) = \\
    &= \int_{\mathbb{R}} \dd{y} W(y,t_0 ) \int_{\mathbb{R}} \frac{\dd{k}}{2 \pi} \exp\left(-Dk^2(t-t_0 ) + ik(x-y)\right) 
    \label{eqn:wxt1}
\end{align}
Recall (CFR 17/10 lecture) that:
\begin{align*}
    \int_{-\infty}^{+\infty} \frac{\dd{k}}{2 \pi} e^{-iak^2 - ibk} = \frac{1}{\sqrt{4 \pi a i}} \exp\left(\frac{i b^2}{4 a} \right)  
\end{align*}
and so with $ia = D(t-t_0 )$ and $b=-(x-y)$ we arrive at:
\begin{align*}
    \int_{\mathbb{R}} \frac{\dd{k}}{2\pi} \exp(-Dk^2(t-t_0) + ik(x-y)) = \frac{1}{\sqrt{4 \pi D(t-t_0 ) }} \exp\left(-\frac{(x-y)^2}{4 D (t - t_0 )} \right) 
\end{align*} 
Substituting back in (\ref{eqn:wxt1}):
\begin{align}
    W(x,t) = \frac{1}{\sqrt{4 \pi D (t-t_0 ) }} \int_{\mathbb{R}} \dd{y} W(y,t_0 ) \exp\left(-\frac{(x-y)^2}{4 D (t-t_0 )} \right)
    \label{eqn:wxt2}
\end{align}

\subsection{Propagators}
Suppose we know with certainty that the particle is in $y = x_0 $ at time $t = t_0$, that is:
\begin{align*}
    W(y, t_0) = \delta(y - x_0)
\end{align*}
Then, substituting in (\ref{eqn:wxt2}) leads to:
\begin{align}
    W(x,t | x_0, t_0) \equiv \frac{1}{\sqrt{4 \pi D (t-t_0 )}} \exp \left(-\frac{(x-x_0)^2}{4 D (t-t_0 )} \right) 
    \label{eqn:prop}
\end{align}
where with $W(x,t|x_0, t_0)$ we denote the probability that the particle will be \textit{around}  position $x$ at time $t$, \textbf{given} it was certainly in $x_0 $ at time $t_0$. $W(x,t|x_0, t_0)$ is also called \textbf{propagator}, as it \q{propagates} the particle from $(x_0 , t_0 )$ to $(x,t)$ as a sort of \textit{continuous transition probability}. This is much more evident if we rewrite (\ref{eqn:wxt2}) as follows (with $y \to x_0$ for simplicity):
\begin{align}
    W(x,t) = \int \dd{x_0 } W(x,t|x_0, t_0) W(x_0, t_0)
    \label{eqn:propagator}
\end{align} 

\begin{comment}
\subsection{Scale invariance} %Sistemare
We will now talk about the concept of \textbf{scale invariance}.\\
We start from:
\begin{align*}
    \partial_t W(x,t) = D \partial_x^2 W(x,t); \qquad x'=\lambda x, t' = \lambda^2 t
\end{align*} 
so that:
\begin{align*}
    \pdv{t'} = \frac{1}{\lambda^2}  \pdv{t}; \qquad \pdv{x'} = \frac{1}{\lambda} \pdv{x} 
\end{align*}
By rearranging, we can write the differential equation as the action of an operator:
\begin{align*}
    (\partial_t - D \partial_x^2) W(x,t) = 0
\end{align*}
which satisfies:
\begin{align*}
    \pdv{t} - D \pdv[2]{x} = \frac{1}{\lambda^2} \left(\pdv{t'} - D \pdv[2]{{x'}} \right)  
\end{align*}
So if $W(x,t)$ is a solution, then also $W(\lambda x, \lambda^2 t)$ is a solution. For a general integral:
\begin{align*}
    W(x,t|0,0) &=  (4 \pi D t)^{-1/2} \exp\left(-\frac{x^2}{4D t} \right) \\
    W(\lambda x, \lambda^2 t | 0, 0) &= (4 \pi D \lambda^2 t)^{-1/2} \exp\left(-\frac{\cancel{\lambda^2} x^2}{4 D t\cancel{ \lambda^2}} \right)\\
     &= \frac{1}{\lambda} W(x,t|0,0)  \\
\end{align*}  
But why are we getting an extra factor of $\lambda$?\\
Recall that $W(x,t)$ is a probability density, so that it is normalized:
\begin{align*}
    1 = \int_{-\infty}^{\infty} \dd{x} W(x,t)
\end{align*}  
So, if we rearrange:
\begin{align*}
    \lambda W(\lambda x, \lambda^2 t | 0, 0) = W(x,t | 0,0)
\end{align*}
and then integrate both sides:
\begin{align*}
    \int \dd{x} \lambda W(\lambda x, \lambda^2 t|0,0) = \int \dd{z} W(z, \lambda^2 t|0,0) = 1
\end{align*}
The two integrals are the same up to a change of variables: $x' = \lambda x$, $\dd{x'} = \lambda \dd{x}$.\\
By choosing $\lambda= 1/ \sqrt{t}$ we get:
\begin{align*}
    W(x,t|0,0) = \frac{1}{\sqrt{t}} W\left(\frac{x}{\sqrt{t}}, 1|0,0 \right) = \frac{1}{\sqrt{t}} f\left(\frac{x}{\sqrt{t}} \right) 
\end{align*}   
Note that this property can be derived even if we do not know the explicit solution:
\begin{align*}
    f(z) = \frac{1}{\sqrt{4 \pi D}} \exp\left(-\frac{z^2}{4D} \right) 
\end{align*}
In fact, by an argument of dimensional analysis, note that $[D] = L^2/t$, and so $[Dt] = [x^2]$. Recall that $[W] = 1/x$, as it is a pdf, and $W\dd{x}$ is a pure number. So:
\begin{align*}
    W(x,t|0,0) = \frac{1}{x} \frac{x}{\sqrt{D t}} ) = \frac{1}{\sqrt{Dt}} \underbrace{\frac{\sqrt{Dt}}{x} F \left(\frac{x}{\sqrt{Dt}} \right)}_{f(x/\sqrt{Dt})}  
\end{align*}  
where $F$ is dimensionless, and $1/x$ restores the correct dimensions.\\
But if we consider also the initial conditions, we have an extra parameter that can be added to the function:
\begin{align*}
    W(x,t|x_0, t_0)
\end{align*}
However, by translational invariance, we can simply translate time and space:
\begin{align*}
    W(x-x_0, t-t_0 | 0,0)
\end{align*}
\end{comment}

\subsection{Properties}
Let's explorer some properties of (\ref{eqn:propagator}).\\

\begin{enumerate}
    \item \textbf{ESCK property}. Let's propagate a particle from a starting point $(x_0, t_0 )$ to two different end points $(x_1 , t_1 )$ and $(x_2 , t_2 )$:
    \begin{align}
        \label{eqn:wx1}
        W(x_1, t_1) &= \int \dd{x_0} W(x_1, t_1|x_0, t_0) W(x_0, t_0) \\
        W(x_2, t_2) &= \int \dd{x_0} W(x_2, t_2|x_0, t_0) W(x_0, t_0) \label{eqn:wx2}
    \end{align}
    We can also propagate to $(x_2, t_2 )$ starting from $(x_1, t_1)$:
    \begin{align}
        W(x_2, t_2) = \int \dd{x_1} W(x_2, t_2 | x_1, t_1) W(x_1, t_1)
        \label{eqn:wx12}
    \end{align}  
    Now, if we substitute (\ref{eqn:wx1}) in (\ref{eqn:wx12}) we get:
    \begin{align*}
        W(x_2, t_2) = \iint \dd{x_1} \dd{x_0} W(x_2, t_2 | x_1, t_1) W(x_1, t_1 | x_0, t_0) W(x_0, t_0)
    \end{align*} 
    By comparing this expression with (\ref{eqn:wx2}), we find that:
    \begin{align*}
        W(x_2, t_2 | x_0, t_0) = \int \dd{x_1} W(x_2, t_2 | x_1, t_1) W(x_1, t_1 | x_0, t_0)
    \end{align*}
    That is, the propagator between two \textit{points} $A$ and $B$ can be obtained by multiplying the propagators between $A \to C$ and $C \to B$ and summing over \textit{all possible choices} of $C$. This property is the Einstein-Smoluchowski-Kolmogorov-Chapman relation (\textbf{ESCK}).
    \item \textbf{Moments}. Consider two instants $t_1 \neq t_2$, and suppose we want to compute $\langle x(t_2) x(t_1) \rangle$, supposing that the particle started in $x=0$ at $t=0$. Applying the definition of an expected value:
    \begin{align*}
        \langle x(t_2) x(t_1) \rangle = \iint \dd{x_1} \dd{x_2} \mathbb{P}(x_2, t_2; x_1, t_1|0,0) x_2 x_1
    \end{align*}
    where $\mathbb{P}(x_2, t_2; x_1,t_1|0,0)$ is the \textit{joint pdf} of a particle being around $x_1 $ at $t_1 $ and around $x_2 $ at $t_2 $, given the \textit{initial position} in $x=0$ at $t=0$.\\
    Recall from probability theory that:
    \begin{align*}
        &\mathbb{P}(x_2, t_2; x_1, t_1;0,0) &=& \quad \mathbb{P}(x_2,t_2;x_1,t_1|0,0) \mathbb{P}(0,0)  \\
        \Rightarrow\> &\mathbb{P}(x_2, t_2; x_1, t_1|0,0) &=& \quad \frac{\mathbb{P}(x_2, t_2; x_1, t_1; 0,0)}{\mathbb{P}(0,0)} = \frac{W(x_2, t_2|x_1, t_1)W(x_1,t_1|0,0)\cancel{W(0,0)}}{\cancel{W(0,0)}}\\
        \span  &=& \quad W(x_2, t_2 | x_1,t_1) W(x_1, t_1 | 0,0)
    \end{align*}
    Recalling the result in (\ref{eqn:prop}) we can now compute:
    \begin{align*}
    \langle x(t_2) x(t_1) \rangle &= \iint_{\mathbb{R}^2} \dd{x_1} \dd{x_2} x_1 x_2 \frac{\exp\left(-\frac{(x_2 - x_1)^2}{4D(t_2 -t_1)} \right) }{\sqrt{4 \pi D (t_2 -t_1)}} \frac{\exp\left(-\frac{x_1^2}{4 D t_1} \right)}{\sqrt{4 \pi D t_1}} 
\intertext{By changing variables ($x_1 = y_1$, $x_2 - x_1 = y_2$) we arrive at:}
    &= \frac{1}{\sqrt{4 \pi D (t_2-t_1) }}  \frac{1}{\sqrt{4 \pi D t_1}} \iint_{\mathbb{R}^2} \dd{y_1} \dd{y_2} y_1 (y_1 + y_2)\exp\left(-\frac{y_2^2}{4D(t_2 -t_1)} - \frac{y_1^2}{4D t_1} \right) =\\
    &\underset{(a)}{=}  \frac{1}{\sqrt{4 \pi D(t_2-t_1)}} \frac{1}{\sqrt{4 \pi D t_1}} \int \dd{y_1} y_1^2 \exp\left(-\frac{y_1^2}{4 D t_1} \right)  \cdot \int \dd{y_2} \exp\left(-\frac{y_2^2}{4  D (t_2-t_1) } \right) =\\
    &\underset{(b)}{=}  
    \frac{1}{\sqrt{\bcancel{4 \pi D(t_2 -t_1)}}} \frac{1}{\sqrt{\cancel{4 \pi D t_1}}} \left(2 D t_1\cancel{ \sqrt{4 \pi D t_1 }}\right) \left(\sqrt{\bcancel{4 \pi D (t_2 - t_1)}}\right)=  
    2D t_1
\end{align*}
In (a) we note that by expanding $y_1(y_1+y_2)$, the term with $y_1 y_2$ is an odd function integrated over a symmetric domain, that results in $0$. So, only the term with $y_1^2$ remains, allowing the integral's factorization. Then, in (b), we compute the Gaussian integrals, \textit{supposing} $t_1 < t_2$ (so that $t_2 - t_1 > 0$) and recalling:
\begin{align*}
    \int_{-\infty}^{+\infty} \exp\left(-\frac{1}{2} a x^2 \right) \dd{x} &= \sqrt{\frac{2 \pi}{a} }\\ \int_{-\infty}^{+\infty} x^2 \exp\left(-\frac{1}{2} a x^2 \right) &= -2 \dv{a} \int_{-\infty}^{+\infty} \exp \left(-\frac{1}{2} a x^2 \right)\dd{x} = \sqrt{\frac{2 \pi}{a}} \frac{1}{a} 
\end{align*}  
The case when $t_1 > t_2$ leads to a similar result, with $t_1 \leftrightarrow t_2$. Thus, in general:   
\begin{align*}
    \langle x(t_1) x(t_2) \rangle = 2D \min(t_1, t_2)
\end{align*} 
\end{enumerate}



Generalizing: %Sistemare
\begin{align*}
    \mathbb{P}(x_i, t_i; i=0, \dots, n) &= \mathbb{P}(x_n, t_n; x_{n-1}, t_{n-1}; \dots; x_1, t_1; x_0, t_0) =\\
    &= \prod_{i=1}^n W(x_i, t_i | x_{i-1}, t_{i-1}) W(x_0, t_0)
\end{align*}
This is the joint probability for a \textit{discrete trajectory}, meaning that we care only about what happens at certain discrete times.\\
For the average value of a generic function $f$ of the trajectory points:
\begin{align*}
    \langle f(x(t_n), x(t_{n-1}), \dots, x(t_0)) \rangle
\end{align*}  
we need to use the joint probability:
\begin{align*}
    = \int \prod_{i=0}^n W(x_i, t_i; i=0, \dots, n) \cdot f(x_n, x_{n-1}, \dots, x_0)
\end{align*}
In the next lecture we will try to see how to generalize this kind of calculation to a function that also depends on the \textit{in between points}, that is on a \textit{infinite set of values of the trajectory}. For example:
\begin{align*}
    \langle \exp \left(-\int_0^t a(\tau) x(\tau) \dd{\tau}\right) \rangle
\end{align*}  
depends on the \textit{whole} trajectory.
\end{document}
