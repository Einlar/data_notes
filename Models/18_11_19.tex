%&latex
%
\documentclass[../template.tex]{subfiles}
\begin{document}

\section{Introduction}
\lesson{?}{18/11/19}

We want to show that there are cases where the stochastic equation (or the resulting path integral) assume a particular form that is theoretically advantageous to be studied in an analytical way, leading to the \textit{Feynmann-Kac} formula, useful both in stochastic processes and in quantum mechanics (note that, in the latter, it needs to be generalized to complex numbers - which isn't rigorous, but still leads to exact results).

During last lecture, when discussing the Harmonic Oscillator in the overdamped limit, we wrote that:
\begin{align*}
    \dd{x} = -k x \dd{t} + \sqrt{2D} \dd{B} \qquad k = \frac{m\omega^2}{\gamma} 
\end{align*}
Then, recall that:
\begin{align*}
    W(x,t|x_0,0) = \exp\left(-\frac{x^2 - x_0^2}{4D}k + kt \right) \langle \exp\left(-\int_0^t V(x(\tau))\dd{\tau}\right) \delta(x(t)-x) \rangle_W 
\end{align*}
where the average is intended to be computed in the Wiener measure:
\begin{align*}
    \langle \cdots \rangle_W = \int \prod_{\tau = 0}^{t} \frac{\dd{x(\tau)}}{\sqrt{4 \pi D} \dd{\tau}} \exp\left[-\frac{1}{4D} \int_0^t \dot{x}^2 (\tau )\dd{\tau}\right] \qquad V(x) = \frac{k^2 x^2}{4D} 
\end{align*}
Integrals of this kind appear quite often when a particle moves in a 3D potential. Our goal is now to consider the more general case of a particle moving in a conservative force-field, and see how the average:
\begin{align*}
    \langle \exp\left(-\int_0^t V(x(\tau)) \dd{\tau} \right) \delta(x(t)-x)\rangle_W \equiv W_B(x,t)
\end{align*} 
will reappear, i.e. we will observe how general problems have a similar formulation.
Note that $V(x)$ is \textit{proportional} to the original harmonic potential:
\begin{align*}
    U(x) = \frac{1}{2} m \omega^2 x^2 
\end{align*}  

\section{Particle in a conservative force-field}
Let's consider a particle in a 3D space $\bm{r} = (x_1, x_2, x_3)^T$, immersed in a conservative force-field $F(\bm{r}) = -\bm{\nabla} U(\bm{r})$ with potential $U(\bm{r})$. Then:
\begin{align*}
    \dd{\bm{r}} = \bm{f}(\bm{r})  \dd{t} + \sqrt{2D} \dd{\bm{B}}
\end{align*}     
with $B= (B_1, B_2 , B_3 )^T$ and:
\begin{align*}
    \Delta B_\alpha \sim \frac{1}{\sqrt{2 \pi \Delta t} } \exp\left(-\frac{\Delta B^2_\alpha}{2 \Delta t} \right)
\end{align*}
with $\bm{f} = \bm{F}/\gamma$, and $\gamma = 6 \pi \eta a$. In vector notation:
\begin{align*}
    \Delta \bm{B} \sim \exp\left(-\frac{(\Delta \bm{B})^2}{2 \Delta t} \right) \frac{1}{(2 \pi \Delta t)^{3/2}} 
\end{align*}  
If we now discretize the problem:
\begin{align*}
    \Delta \bm{r}_i = \bm{r} (t_i) - \bm{r}(t_i)
\end{align*}
we can rewrite that equation as:
\begin{align*}
    \Delta \bm{r}_i = \bm{f}_{i-1} \Delta t_i + \sqrt{2D} \Delta \bm{B}_i
\end{align*}
We can then repeat all the steps we've seen in the 1D case, leading to:
\begin{align*}
    \dd{P}(\Delta \bm{B}_1, \dots, \Delta \bm{B}_N) &= \prod_{i=1}^N \frac{\dd[3]{\Delta B}}{(2 \pi \Delta t)^{3/2}} \exp\left(-\sum_{i=1}^N \frac{\Delta \bm{B}_i^2}{2 \Delta t_i} \right)\\
    \dd{P}(\Delta \bm{r}_1, \dots, \Delta \bm{r}_N) &= \prod_{i=1}^N \frac{\dd[3]{\Delta \bm{r}_i}}{(4 \pi D \Delta t_i)^{3/2}} \exp\left[-\frac{1}{4D} \sum_{i=1}^N \frac{(\Delta \bm{r}_i - \bm{f}_{i-1} \Delta t_i)^2}{\Delta t_i}  \right] 
\end{align*}
(Note that, in the textbook, instead of $\bm{f}_{i-1}$ they are using the Stratonovich prescription $(\bm{f}_i + \bm{f}_{i-1})/2$, complicating the jacobian for a change of variables, while we are using Ito's. In the end, however, the final result will not depend on this choice - at least for this case).

Expanding the exponential:
\begin{align*}
    -\frac{1}{4D} \sum_{i=1}^N \left[\frac{\Delta \bm{r}_i^2}{\Delta t_i} + \bm{f}_{i-1}^2 \Delta t_i - 2 \Delta \bm{r_i} \cdot \bm{f}_{i-1} \right]
\end{align*}
and substituting back:
\begin{align*}
    \dd{P}(\{\Delta \bm{r}_i\}) = \underbrace{\prod_{i=1}^N \frac{\dd[3]{\Delta r_i}}{(4 \pi D \Delta t_i)^{3/2}} \exp\left[-\frac{1}{4D} \sum_{i=1}^N \frac{\Delta \bm{r}_i^2}{\Delta t_i}  \right] }_{\dd{_W r}}  \exp\left(-\frac{1}{4D} \underbrace{\sum_{i=1}^N \bm{f}_{i-1}^2 \Delta t_i}_{\displaystyle\int_0^t \bm{f}^2(\bm{r}(\tau)) \dd{\tau} }  + \frac{1}{2D} \underbrace{ \sum_{i=1}^N \bm{f}_{i-1} \cdot \Delta \bm{r}_i}_{\displaystyle \int_0^t \bm{f}(\bm{r}(\tau)) \dd{_J \bm{r}(\tau)}}  \right)
\end{align*}
Note that, for a vector function $h(\bm{r})$, letting $\bm{r}_i = \bm{r}_{i-1} + \Delta \bm{r}_i \Rightarrow \Delta \bm{r}_i = (\Delta x^1_i, \Delta x^2_i, \Delta x_i^3)^T$ leads to the following expansion:
\begin{align*}
    \Delta h_i = h(\bm{r}_i) - h(\bm{r}_{i-1}) = \sum_{\alpha =1}^3
 \Delta x_i^\alpha \pdv{x^\alpha} h(\bm{r}_{i-1}) + \frac{1}{2} \sum_{\alpha, \beta = 1}^3 \Delta x_i^\alpha \cdot \Delta x_i^\beta \pdv[2]{}{x^\alpha}{x^\beta} h(\bm{r}_{i-1}) + \dots \end{align*}  
Taking the continuum limit we make the following substitution:
\begin{align*}
    \Delta x_i^\alpha \Delta x_i^\beta \to \Delta t_i 2 D \delta^{\alpha \beta}
\end{align*}
Then, summing all the increments:
\begin{align*}
    h(\bm{r}_N) - h(\bm{r}_0) = \sum_{i=1}^N \Delta h_i = \sum_{\alpha = 1}^3 \sum_i \pdv{x^\alpha} h_{i-1} \Delta x_i^\alpha + D \sum_{\alpha =1}^3 \pdv[2]{{x^\alpha}} h_{i-1} \Delta t_i
 \end{align*}
 and then, in the continuum limit:
 \begin{align*}
     h(\bm{r}(t))- h(\bm{r}(0)) = \int_0^t \bm{\nabla} h \cdot \dd{_J \bm{r}} + D \int_0^t \nabla^2 h \dd{t}
 \end{align*}
 Note that now, by rearranging, we find a formula for the integral we needed:
 \begin{align*}
     \int_0^t \bm{\nabla} h \cdot \dd{_J \bm{r}} = h(\bm{r}(t)) - h(\bm{r}(0)) - D\int_0^t \nabla^2 h \dd{t}
 \end{align*}
 In fact, we can use it for solving:
 \begin{align*}
     \int_0^t \bm{f}(\bm{r}(\tau)) \dd{_J \bm{r}(\tau)}
 \end{align*}
 as we know that the force $\bm{f}$ comes from a potential:
 \begin{align*}
     \int_0^t \bm{f} \cdot \dd{_J \bm{r}} = -\frac{1}{\gamma} \int \bm{\nabla} U \cdot \dd{_I} \bm{r} = -\frac{1}{\gamma} \left[U(\bm{r}(t)) - U(\bm{r}(0)) - D \int_0^t \nabla^2 U \cdot \dd{\tau}\right] 
 \end{align*} 
 Substituting back in the first formula:
 \begin{align*}
     \dd{P}(\{\Delta \bm{r}_i\}) \to \dd{_W} \bm{r} \exp\left(-\frac{1}{4 D } \int_0^t V(\bm{r}(\tau))\dd{\tau} \right) \exp\left(-\frac{1}{2D \gamma} [U(\bm{r}(t)) - U(\bm{r}(0))]\right)
 \end{align*}
 where:\marginpar{There may be missing factors}
 \begin{align*}
     V= \bm{f}^2 - \frac{2D}{\gamma}  \nabla^2 U = \bm{f}^2 - 2D \bm{\nabla} \cdot \bm{f}
 \end{align*}
 (recalling that $\bm{\nabla}U/\gamma = - \bm{f}$).

 Now:
 \begin{align*}
     W(\bm{r},t | \bm{r}_0, 0) &= \int \dd{P} \delta(\bm{r}(t) - \bm{r}) = \langle \delta(\bm{r}(t)- \bm{r}(0)) \rangle = \\
     &= \int \dd{_W \bm{r}} \exp\left(-\frac{1}{4D} \int_0^t V(\bm{r}(\tau)) \dd{\tau} \right) \delta(\bm{r}(t) - \bm{r}) \exp\left(-\frac{1}{2D \gamma} (U(\bm{r}) - U(\bm{r}_0))\right) =\\
     &= \langle \exp\left(-\frac{1}{4D} \int_0^t V \dd{\tau} \right)  \delta (\bm{r}(t) - \bm{r})\rangle_W \exp\left(-\frac{1}{2D \gamma} (U(\bm{r})- U(\bm{r}_0))\right)
 \end{align*}
 which is the general expression we were searching for.

\subsection{Correspondence with Quantum Mechanics}
An important result (here stated for the 1D case, for notational simplicity) is the following. Define:
\begin{align}
    W_B(x,t) \equiv \langle \exp\left(-\int_0^t V(x(\tau)) \dd{\tau}\right) \delta(x(t) - x) \rangle_W
    \label{eqn:Wb}
\end{align}
(the $4D$ constant has been absorbed by $V$). Then the following holds:
\begin{align}
    \partial_t W_B(x,t) = D \partial_x^2 W_B(x,t) - V(x) W_B(x,t)
    \label{eqn:diffusion}
\end{align}
Recall the Schr\"odinger equation:
\begin{align*}
    i\hbar \partial_t \psi(x,t) = -\frac{\hbar^2}{2m} \partial_x^2 \psi(x,t) + v(x) \psi(x,t) 
\end{align*}
So by mapping $t \to -it$ (passing to \q{imaginary time}), and $\psi(-it, x) \equiv \hat{\psi}(t,x)$  we can cancel the $i$ the Schr\"odinger equation, leading to:
\begin{align*}
    \hbar \pdv{t} \hat{\psi} = \underbrace{\frac{\hbar^2}{2 m}}_{D} \partial_x^2 \hat{\psi} - \underbrace{\frac{v(x)}{\hbar}}_{V}  \hat{\psi}  
\end{align*}
which is equivalent to the Bloch equation.

We want now to prove that (\ref{eqn:Wb}) satisfies (\ref{eqn:diffusion}). To do this, we discretize once again:
\begin{align}
     \psi_{N+1}(x) = \int \prod_{i=1}^{N+1} \frac{\dd{x_i}}{\sqrt{4 \pi D \Delta t_i} } \exp\left(-\sum_{i=1}^{N+1} \frac{(x_i - x_{i-1})^2}{4 D \Delta t_i} - \sum_{i=1}^{N+1} \Delta t_i V(x_i)\right) \delta(x_{N+1}-x)
     \label{eqn:psix}
\end{align} 
Choose $\Delta t_i \equiv \epsilon$, such that $t_{N+1} = (N+1) \epsilon = t \Rightarrow \epsilon = t/(N+1)$. Then:
\begin{align*}
    W_B(x,t) = \lim_{N \to \infty} \psi_{N+1}(x)
\end{align*}  
Integrating over $x_{N+1}$:
\begin{align*}
    (\ref{eqn:psix}) = \frac{1}{\sqrt{4 \pi D \epsilon}}\int \prod_{i=1}^N \frac{\dd{x_i}}{\sqrt{4 \pi D \epsilon}} \exp\left(-\sum_{i=1}^N \frac{(x_i - x_{i-1}^2)}{4 D \epsilon} - \sum_{i=1}^N \epsilon V(x_i)\right) \exp\left(\frac{-(x_{N+1} - x_N)^2}{4 D \epsilon } - \epsilon V(x_{N+1}) \right) =
\end{align*} 
Then $x_{N+1} \equiv x$ and:
\begin{align*}
    = \int \frac{\dd{x_N}}{\sqrt{4 \pi D \epsilon }} \exp\left(-\frac{(x-x_N)^2}{4 D \epsilon} - \epsilon V(x) \right) \hlc{Yellow}{\frac{1}{\sqrt{4 \pi D \epsilon}}  \int \prod_{i=1}^{N-1} \frac{\dd{x_i}}{\sqrt{4 \pi D \epsilon }} \exp\left(
    -\sum_{i=1}^{N} \frac{(x_i - x_{i-1})^2}{4 D \epsilon} - \epsilon\sum_{i=1}^{N} V(x_i)    
    \right)}
\end{align*}
The highlighted part is equal to:
\begin{align*}
    = \int \prod_{i=1}^N \frac{\dd{y_i}}{\sqrt{4 \pi D \epsilon}}\exp\left(-\sum_{i=1}^N \left[\frac{(y_i - y_{i-1})^2}{4 D \epsilon} + \epsilon V(y_i)\right]\right) \delta(y_N - x_N) = \psi_N(x_N) 
\end{align*}
and so:
\begin{align*}
    \psi_{N+1}(x) = e^{-\epsilon V(x) }\int \frac{\dd{x_N}}{\sqrt{4 \pi D \epsilon }} \exp\left(-\frac{(x-x_N)^2}{4 D \epsilon} \right) \psi_N(x_N)
\end{align*}
which looks like an evolution equation for $\psi$.

If we now change variables:
\begin{align*}
    z \equiv \frac{x - x_N}{\sqrt{2 D \epsilon}} 
\end{align*}
we arrive at:
\begin{align*}
    \psi_{N+1}(x) = e^{-\epsilon V(x)} \int \frac{\dd{z}}{\sqrt{2 \pi}}\exp\left(-\frac{z^2}{2} \right)  \psi_N(x- z\sqrt{2 D \epsilon})
\end{align*}
$z$ is small, and so we can Taylor expand:
\begin{align*}
    &= e^{-\epsilon V(x)} \int \frac{\dd{z}}{\sqrt{2 \pi}} \exp\left(-\frac{z^2}{2} \right)  \left[\psi_N(x)  - z \sqrt{2 D \epsilon} \psi_N'(x) + z^2 D \epsilon \psi_N'' (x) + O(z^3 \epsilon^{3/2})\right] =\\
    &=e^{-\epsilon V(x)}[\psi_N(x) + D \epsilon \psi_N''(x) + O(\epsilon^2) ]
\end{align*} 
expanding also the exponential:
\begin{align*}
    e^{-\epsilon V(x)} = \left(1- \epsilon V(x) + \frac{\epsilon^2 V(x)^2}{2}  + \dots \right)
\end{align*}
we arrive at:
\begin{align*}
    = \psi_N(x) + D \epsilon \psi_N''(x) - \epsilon V(x) \psi_N(x) + O(\epsilon^2)
\end{align*}
Rearranging:
\begin{align*}
    \frac{\psi_{N+1} - \psi_N}{\epsilon} = D \psi_N'' - V \psi_N 
\end{align*}
And when $\epsilon \to 0$:
\begin{align*}
    \partial_t W_B(x,t) = D \partial_x^2 W_B(x,t) - V(x) W_B(x,t)
\end{align*} 
which is Bloch's equation. 

So we can \textit{solve} this partial differential equation by simply generating random \textit{paths} going from $x_0$ at time $0$ to $x$ at time $t$, computing the exponential of the integral $\int_0^t V(x(\tau)) \dd{\tau}$ and averaging the results:
\begin{align*}
    W_B(x,t) \equiv \langle \exp\left(-\int_0^t V(x(\tau))\dd{\tau}\right) \delta(x(t)-x)\rangle_W
\end{align*}

\section{Variational methods}
One powerful technique to solve Wiener integral is through \textit{variational methods}. 

Consider a symmetric $N\times N$ matrix $A$ ($A = A^T$) and the following gaussian integral:
\begin{align*}
    \int \prod_{i=1}^N \exp\left(-\frac{1}{2} \bm{x}^T A \bm{x} + \bm{b}^T \bm{x}  \right) = \frac{(2 \pi)^{N/2}}{|A|^{1/2}} \exp\left(\frac{1}{2} \bm{b}^T A^{-1} \bm{b} \right) = \frac{(2\pi)^{N/2}}{|A|^{1/2}} \exp\left(\operatorname{Stat}_{\bm{x}} \left[-\frac{1}{2} \bm{x}^T A \bm{x} + \bm{b} \cdot \bm{x} \right] \right) 
\end{align*}
where:
\begin{align*}
    \operatorname{Stat}_{\bm{x}} F(\bm{x}) = F(\bm{x}_c); \qquad \bm{x_c} \text{ such that } \forall i \pdv{F(\bm{x})}{x_i} \Big|_{\bm{x} = \bm{x}_c} = 0
\end{align*}
In this case:
\begin{align*}
    \bm{F} = -\frac{\bm{x}^T A \bm{x}}{2} + \bm{b}^T \bm{x} \Rightarrow \partial_i F = - \sum_{j} A_{ij} x_j + b_i = - A\bm{x} + \bm{b} \overset{!}{=}  0 \Rightarrow\bm{x}_c = A^{-1}\bm{b}  
\end{align*}
Then, substituting in the original expression:
\begin{align*}
    F(\bm{x}_c) = - \bm{x}_c^T A \bm{x}_c + \bm{b} \cdot \bm{x}_c = \frac{1}{2} \bm{b}^T A^{-1} \bm{b}
\end{align*}
gives back the correct exponent for the integral's result.

This interesting idea can be applied also to Wiener integrals:
\begin{align*}
    W(x,t|x_0,0) &= \int \prod_{\tau = 0}^t \frac{\dd{x(\tau)}}{\sqrt{4 \pi D \dd{\tau}}} \exp\left(-\frac{1}{4D} \int_0^t \dot{x}^2 (\tau) \dd{\tau} \right) \delta(x-x(t)) = \\
    &=  "\lim_{N \to \infty}"  \int \prod_{i=1}^{N} \frac{\dd{x_i}}{\sqrt{4 \pi D \Delta t_i }} \exp\left(- \sum_{i=1}^N \frac{(x_i - x_{i-1})^2}{4 D \Delta t_i} \right)  \delta(x- x_N)
\end{align*}
Integrating over $x_N$:
\begin{align*}
    &= \frac{1}{\sqrt{4 \pi D \Delta t_i}} \int \prod_{i=1}^{N-1} \frac{\dd{x_i}}{\sqrt{4 \pi D \Delta t_i}} \exp\left(-\sum_{i=1}^N \frac{(x_i - x_{i-1})^2}{4 D \Delta t_i} \right) \Big|_{x_N = x} 
\end{align*} 
and now the \textit{constraint} $\delta(x - x(t))$ is \textit{inducing} a \textit{linear term} in the exponential:
\begin{align*}
    \sum_{i=1}^{N-1} \frac{(x_i - x_{i-1})^2}{4 D \Delta t_i}  - \underbrace{\frac{1}{4 D \Delta t_N} (x- x_{N-1})^2 }_{\displaystyle \frac{1}{4 D \Delta t_N} (x^2 - 2x x_{N-1} + x_{N-1}^2) } 
\end{align*}    
Passing to the continuum limit, we substitute the finite vector $\{x_i\}$ with the infinite one $\{x(\tau)\}$, so that:
\begin{align*}
    W(x,t|x_0,0) = N \exp\left( \operatorname{Stat}_{\{x(\tau)\}} -\frac{1}{4 D} \int \dot{x}^2 (\tau) \dd{\tau} \right)
\end{align*}  
where $x(0) = x_0$ and $x(t) = x$. Recall that:
\begin{align*}
    F(\bm{x}) = F(\bm{x}_c) + \sum_{i=1}^N X_i \pdv{x_i} F(\bm{x}_c) + \dots \qquad \bm{x} = \bm{x}_c + \bm{X}
\end{align*}  
and the stationarity conditions are $\partial_i F(\bm{x}_c) = 0$.
Differentiating:
\begin{align*}
    \dot{x}(\tau) = \dot{x}_c(\tau) + \dot{X} (\tau) \qquad x_c(\tau) = \begin{cases}
        x_0 & \tau = 0\\
        x & \tau = t
    \end{cases}
\end{align*}
Then, computing the integral $\bm{\dot{x}}^2$ with these coordinates \q{centered} on $\bm{x}_c$: 
\begin{align*}
    \int_0^t (\dot{\bm{x}}_c + \dot{\bm{X}})^2 \dd{\tau} = \int_0^t \dot{\bm{x}_c}^2 \dd{\tau} + 2 \int_0^t \dot{\bm{x}_c} \dot{\bm{X}} \dd{\tau} + \int_0^t \dot{\bm{X}}^2 (\tau) \dd{\tau}
\end{align*}
Integrating by parts leads to:
\begin{align*}
    = \dot{\bm{x}_c}(\tau) \bm{X}(\tau) \Big|_0^t - \int_0^t \ddot{\bm{x}_c}(\tau) \bm{X}(\tau) \dd{\tau}
\end{align*}
then $X(\tau) = 0$ both at $\tau = 0,t$, and with the boundary conditions $\ddot{x}_c = 0$, $x_c(0) = x_0$ and $x_c(t) = x$ leads to the \textit{line solution}:
\begin{align*}
    x_c(\tau) = x_0 + \frac{\tau}{t}(x- x_0)   \quad \dot{x}_c(\tau) = \frac{x-x_0}{t} 
\end{align*}     
Note that $X$ does not depend on the boundary conditions, and so:
\begin{align*}
    W(x,t|x_0,0) &= \mathcal{N}(t) \exp\left(\operatorname{Stat}_{\{x(\tau)\}}  -\frac{1}{4D}\int \dot{x}^2 (\tau) \dd{\tau} \right) = \\
    &= \mathcal{N}(t) \exp\left(-\frac{1}{4D} \int_0^t \dot{x_c}^2 (\tau) \dd{\tau} \right) = \mathcal{N}(t) \exp\left(-\frac{1}{4D} \int_0^t \left(\frac{x-x_0 }{t} \right)^2 \dd{\tau}\right) = 
    \\
    &= \mathcal{N}(t) \exp\left(-\frac{1}{4D} \frac{(x-x_0)^2}{t}  \right)
\end{align*} 
and $\mathcal{N}(t)$ is just a normalization constant that can be determined by integration:
\begin{align*}
    \mathcal{N}(t) = \frac{1}{\sqrt{4 D \pi t}} 
\end{align*} 
 \end{document}
